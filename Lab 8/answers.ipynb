{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02c6561f-e7cd-4481-8497-59936b8e37e5",
   "metadata": {},
   "source": [
    "# KNN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30f20d2c-0826-4104-a759-d28c7c719bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weight  sweetness level   label   distance\n",
      "3     170                5  Orange   5.024938\n",
      "4     160                6   Apple   5.024938\n",
      "2     150                4  Orange  15.074813\n",
      "0     180                7   Apple  15.074813\n",
      "5     140                3  Orange  25.124689\n",
      "1     200                6   Apple  35.003571\n",
      "   weight  sweetness level   label   distance\n",
      "3     170                5  Orange   5.024938\n",
      "4     160                6   Apple   5.024938\n",
      "2     150                4  Orange  15.074813\n",
      "label\n",
      "Orange    2\n",
      "Apple     1\n",
      "Name: count, dtype: int64\n",
      "Orange\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('fruits.csv')\n",
    "\n",
    "def euclid(x, y):\n",
    "    return ((x[0] - y[0]) ** 2 + (x[1] - y[1]) ** 2) ** 0.5\n",
    "\n",
    "def manhatten(x, y):\n",
    "    return abs(x[0] - y[0]) + abs(x[1] - y[1])\n",
    "\n",
    "def minkowski(x, y, k):\n",
    "    return ((x[0] - y[0]) ** k + (x[1] - y[1]) ** k) ** (1 / k)\n",
    "\n",
    "n_weight = 165\n",
    "n_sweet = 5.5\n",
    "k = 3\n",
    "\n",
    "# note how the function is applied to the entire dataframe\n",
    "df['distance'] = euclid((df['weight'], df['sweetness level']), (165, 5.5))\n",
    "\n",
    "# to sort values use sort_values here; don't forget about the 'by' and 'ascending' parameters\n",
    "df = df.sort_values(by='distance', ascending= True)\n",
    "print(df)\n",
    "\n",
    "# keep k enteries; in pandas slicing includes the last element as well\n",
    "enteries = min(k, len(df))\n",
    "print(df.iloc[: enteries])\n",
    "\n",
    "# note how value counts is used\n",
    "counts = df.iloc[:enteries, ].value_counts('label')\n",
    "print(counts)\n",
    "\n",
    "# use idxmax for the answer\n",
    "print(counts.idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4081897e-6f6c-4c7d-828d-257760a77f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age Blood Pressure Cholesterol Diagnosis\n",
      "0   30           High        High      Sick\n",
      "1   45            Low      Normal   Healthy\n",
      "2   50           High        High      Sick\n",
      "3   35            Low      Normal   Healthy\n",
      "4   60           High        High      Sick\n",
      "5   55            Low      Normal   Healthy\n",
      "6   40           High        High      Sick\n",
      "7   25            Low      Normal   Healthy\n",
      "8   65           High        High      Sick\n",
      "9   45            Low      Normal   Healthy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "p_data = pd.read_csv('patient_data.csv')\n",
    "p_data = p_data.drop('Patient ID', axis = 1)\n",
    "print(p_data)\n",
    "\n",
    "# class to store details about each node in the tree\n",
    "# self.head stores the attribute which is used to classify a patient as healthy or sick. e.g - age, blood pressure, cholesterol\n",
    "# self.end will be true if the node is a leaf node; meaning that we can return the decision we found - whether sick or healthy\n",
    "# self.ans will store sick or healthy based on the data if self.end is true; this value has to be returned once we reach the leaf node\n",
    "# self.next will store links to other nodes in the tree; no. of links depends on no. of unique values in the column of the attribute in head\n",
    "# self.next can have any no. of links.. from 1 to n\n",
    "class Node:\n",
    "    \n",
    "    def __init__(self, ):\n",
    "        self.head = None\n",
    "        self.ans = None\n",
    "        self.next = {}\n",
    "        self.end = False\n",
    "\n",
    "class Decision_Tree:\n",
    "    \n",
    "    # self.root is to store the root node of the tree\n",
    "    def __init__(self,):\n",
    "        self.root = None\n",
    "\n",
    "    # we are using ID3, so info gain formula is used\n",
    "    # classifier represents the decision column, meaning the column we want to predict\n",
    "    # attribute is the current column we are considering for the split\n",
    "    def info_gain(self, data, classifier, attribute):\n",
    "        # gain_data represents the entropy of the entire dataset\n",
    "        gain_data = 0\n",
    "        \n",
    "        for x in data[classifier].unique():\n",
    "            \n",
    "            # p is probability\n",
    "            p = len(data[data[classifier] == x]) / len(data)\n",
    "            \n",
    "            # note log2 is used\n",
    "            gain_data += -p * np.log2(p)\n",
    "\n",
    "        # gain_att is used to represent the weighted sum of the entropy of values in the attribute column\n",
    "        gain_att = 0\n",
    "        \n",
    "        for x in data[attribute].unique():\n",
    "            \n",
    "            # val will store the entropy of the 'x' value of attribute we are considering\n",
    "            val = 0\n",
    "            \n",
    "            for y in data[classifier].unique():\n",
    "                # p is probability\n",
    "                p = len(data[(data[classifier] == y) & (data[attribute] == x)]) / len(data[data[classifier] == y])\n",
    "                # handling situation when p == 0; if let be, this will raise an error\n",
    "                if p == 0:\n",
    "                    continue\n",
    "                # note log2\n",
    "                val += -p * np.log2(p)\n",
    "\n",
    "            # p_att is probability of x\n",
    "            p_x = len(data[data[attribute] == x]) / len(data)\n",
    "            \n",
    "            gain_att += p_x * val\n",
    "\n",
    "        # returning information gain\n",
    "        return gain_data - gain_att\n",
    "\n",
    "    # for choosing the attribute that will split the dataset\n",
    "    def split(self, data, classifier):\n",
    "        \n",
    "        # if only 1 value in the column we want to predict, then no need to further split, just return a leaf node\n",
    "        # with value in the predictor column\n",
    "        if len(data[classifier].unique()) == 1:\n",
    "            ob = Node()\n",
    "            ob.end = True\n",
    "            ob.ans = data[classifier].unique()[0]\n",
    "            return ob\n",
    "        else:\n",
    "            # ob -> creating of tree node\n",
    "            # att -> attribute choosed for splitting\n",
    "            ob = Node()\n",
    "            att = None\n",
    "            info_gain = float('-inf')\n",
    "            for x in data.columns:\n",
    "                if x == classifier:\n",
    "                    continue\n",
    "                val = self.info_gain(data, classifier, x)\n",
    "                if val > info_gain:\n",
    "                    info_gain = val\n",
    "                    att = x\n",
    "            ob.head = att\n",
    "            # now that the attribute is selected, we need to find the datasets for each link of this node\n",
    "            # this depends on the values of the attribute itself\n",
    "            for x in data[att].unique():\n",
    "                ndata = data[data[att] == x]\n",
    "                ndata = ndata.drop(att, axis = 1)\n",
    "                ob.next[x] = self.split(ndata, classifier)\n",
    "            return ob\n",
    "\n",
    "tree = Decision_Tree()\n",
    "tree.root = tree.split(p_data, 'Diagnosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f377dd80-d111-4796-9718-b6793c54e808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "person age =  30\n",
      "person blood pressure =  High\n",
      "person cholesterol =  High\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sick\n"
     ]
    }
   ],
   "source": [
    "u_age = input(f'person age = ')\n",
    "u_blood_pressure = input(f'person blood pressure = ')\n",
    "u_cholesterol = input(f'person cholesterol = ')\n",
    "\n",
    "# dfs traversal to reach leaf node.\n",
    "def dfs(curr, age, blood, cholest):\n",
    "    if curr.end:\n",
    "        return curr.ans\n",
    "    if curr.head == 'Age':\n",
    "        return dfs(curr.next[age], age, blood, cholest)\n",
    "    if curr.head == 'Blood Pressure':\n",
    "        return dfs(curr.next[blood], age, blood, cholest)\n",
    "    return dfs(curr.next[cholest], age, blood, cholest)\n",
    "    \n",
    "print(dfs(tree.root, u_age, u_blood_pressure, u_cholesterol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59d2e8e-2b57-4fc1-8e73-2d3bd9093148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
